{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BRIEF (Binary Robust Independent Elementary Features)\n",
    "\n",
    "_You can view [IPython Notebook](README.ipynb) report._\n",
    "\n",
    "----\n",
    "\n",
    "## Contents\n",
    "\n",
    "- [GOAL](#GOAL)\n",
    "- [Theory](#Theory)\n",
    "- [BRIEF in OpenCV](#BRIEF-in-OpenCV)\n",
    "- [Additional Resources](#Additional-Resources)\n",
    "\n",
    "## GOAL\n",
    "\n",
    "In this chapter:\n",
    "\n",
    "- We will see the basics of BRIEF algorithm\n",
    "\n",
    "## Theory\n",
    "\n",
    "We know SIFT uses 128-dim vector for descriptors. Since it is using floating point numbers, it takes basically 512 bytes. Similarly SURF also takes minimum of 256 bytes (for 64-dim). Creating such a vector for thousands of features takes a lot of memory which are not feasible for resouce-constraint applications especially for embedded systems. Larger the memory, longer the time it takes for matching.\n",
    "\n",
    "But all these dimensions may not be needed for actual matching. We can compress it using several methods like PCA, LDA etc. Even other methods like hashing using LSH (Locality Sensitive Hashing) is used to convert these SIFT descriptors in floating point numbers to binary strings. These binary strings are used to match features using Hamming distance. This provides better speed-up because finding hamming distance is just applying XOR and bit count, which are very fast in modern CPUs with SSE instructions. But here, we need to find the descriptors first, then only we can apply hashing, which doesn't solve our initial problem on memory.\n",
    "\n",
    "BRIEF comes into picture at this moment. It provides a shortcut to find the binary strings directly without finding descriptors. It takes smoothened image patch and selects a set of $ n_d $ $ (x,y) $ location pairs in an unique way (explained in paper). Then some pixel intensity comparisons are done on these location pairs. For eg, let first location pairs be $ p $ and $ q $. If $ I(p)<I(q) $, then its result is 1, else it is 0. This is applied for all the $ n_d $ location pairs to get a $ n_d $-dimensional bitstring.\n",
    "\n",
    "This $ n_d $ can be 128, 256 or 512. OpenCV supports all of these, but by default, it would be 256 (OpenCV represents it in bytes. So the values will be 16, 32 and 64). So once you get this, you can use Hamming Distance to match these descriptors.\n",
    "\n",
    "One important point is that BRIEF is a feature descriptor, it doesn't provide any method to find the features. So you will have to use any other feature detectors like SIFT, SURF etc. The paper recommends to use CenSurE which is a fast detector and BRIEF works even slightly better for CenSurE points than for SURF points.\n",
    "\n",
    "In short, BRIEF is a faster method feature descriptor calculation and matching. It also provides high recognition rate unless there is large in-plane rotation.\n",
    "\n",
    "## BRIEF in OpenCV\n",
    "\n",
    "Below code shows the computation of BRIEF descriptors with the help of CenSurE detector. (CenSurE detector is called STAR detector in OpenCV)\n",
    "\n",
    "NOTE: you need [opencv contrib](https://github.com/opencv/opencv_contrib) to use this. \n",
    "\n",
    "```python\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"../../data/blox.jpg\", 0)\n",
    "# Initiate FAST detector\n",
    "star = cv.xfeatures2d.StarDetector_create()\n",
    "# Initiate BRIEF extractor\n",
    "brief = cv.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "# find the keypoints with STAR\n",
    "kp = star.detect(img, None)\n",
    "# compute the descriptors with BRIEF\n",
    "kp, des = brief.compute(img, kp)\n",
    "\n",
    "img2 = cv.drawKeypoints(img, kp, None, color=(0, 0, 255), flags=0)\n",
    "cv.imwrite(\"output-files/brief-result.png\", img2)\n",
    "cv.imshow(\"Result\", img2)\n",
    "\n",
    "print(brief.descriptorSize())\n",
    "print(des.shape)\n",
    "```\n",
    "\n",
    "The result is below:\n",
    "\n",
    "![brief-result](output-files/brief-result.png)\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "1. Michael Calonder, Vincent Lepetit, Christoph Strecha, and Pascal Fua, \"BRIEF: Binary Robust Independent Elementary Features\", 11th European Conference on Computer Vision (ECCV), Heraklion, Crete. LNCS Springer, September 2010.\n",
    "2. [LSH (Locality Sensitive Hashing)](https://en.wikipedia.org/wiki/Locality-sensitive_hashing) at wikipedia.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
